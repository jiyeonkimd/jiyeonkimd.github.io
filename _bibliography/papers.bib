---
---

@misc{kim2024knowledgeentropydecaylanguage,
  title={Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition}, 
  author={Jiyeon Kim* and Hyunji Lee* and Hyowon Cho and Joel Jang and Hyeonbin Hwang and Seungpil Won and Youbin Ahn and Dohaeng Lee and Minjoon Seo},
  year={2025},
  eprint={2410.01380},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.01380}, 
  code={https://github.com/kaistAI/Knowledge-Entropy},
  abstract={In this work, we investigate how a model's tendency to broadly integrate its parametric knowledge evolves throughout pretraining, and how this behavior affects overall performance, particularly in terms of knowledge acquisition and forgetting. We introduce the concept of knowledge entropy, which quantifies the range of memory sources the model engages with; high knowledge entropy indicates that the model utilizes a wide range of memory sources, while low knowledge entropy suggests reliance on specific sources with greater certainty. Our analysis reveals a consistent decline in knowledge entropy as pretraining advances. We also find that the decline is closely associated with a reduction in the model's ability to acquire and retain knowledge, leading us to conclude that diminishing knowledge entropy (smaller number of active memory sources) impairs the model's knowledge acquisition and retention capabilities. We find further support for this by demonstrating that increasing the activity of inactive memory sources enhances the model's capacity for knowledge acquisition and retention.},
  venue={ICLR 2025 Oral},
  workshop={Best Paper Award, Towards Knowledgeable Foundation Models @AAAI 2025 Workshop},
  selected={true}
}

@misc{lee2024doesvisionlanguageadaptationimpact,
  title={How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?}, 
  author={Seongyun Lee* and Geewook Kim* and Jiyeon Kim* and Hyunji Lee and Hoyeon Chang and Sue Hyun Park and Minjoon Seo},
  year={2025},
  eprint={2410.07571},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.07571}, 
  abstract={Vision-Language adaptation (VL adaptation) transforms Large Language Models (LLMs) into Large Vision-Language Models (LVLMs) for multimodal tasks, but this process often compromises the inherent safety capabilities embedded in the original LLMs. Despite potential harmfulness due to weakened safety measures, in-depth analysis on the effects of VL adaptation on safety remains under-explored. This study examines how VL adaptation influences safety and evaluates the impact of safety fine-tuning methods. Our analysis reveals that safety degradation occurs during VL adaptation, even when the training data is safe. While safety tuning techniques like supervised fine-tuning with safety datasets or reinforcement learning from human feedback mitigate some risks, they still lead to safety degradation and a reduction in helpfulness due to over-rejection issues. Further analysis of internal model weights suggests that VL adaptation may impact certain safety-related layers, potentially lowering overall safety levels. Additionally, our findings demonstrate that the objectives of VL adaptation and safety tuning are divergent, which often results in their simultaneous application being suboptimal. To address this, we suggest the weight merging approach as an optimal solution effectively reducing safety degradation while maintaining helpfulness. These insights help guide the development of more reliable and secure LVLMs for real-world applications.},
  venue={ICLR 2025},
  selected={true}
}

@inproceedings{yoon-etal-2024-listt5,
  title = "{L}ist{T}5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval",
  author = "Yoon, Soyoung  and
    Choi, Eunbi  and
    Kim, Jiyeon  and
    Yun, Hyeongu  and
    Kim, Yireun  and
    Hwang, Seung-won",
  editor = "Ku, Lun-Wei  and
    Martins, Andre  and
    Srikumar, Vivek",
  month = aug,
  year = "2024",
  address = "Bangkok, Thailand",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.acl-long.125",
  doi = "10.18653/v1/2024.acl-long.125",
  pages = "2287--2308",
  abstract = "We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and compare our model on the BEIR benchmark for zero-shot retrieval task, demonstrating that ListT5 (1) outperforms the state-of-the-art RankT5 baseline with a notable +1.3 gain in the average NDCG@10 score, (2) has an efficiency comparable to pointwise ranking models and surpasses the efficiency of previous listwise ranking models, and (3) overcomes the lost-in-the-middle problem of previous listwise rerankers. Our code, model checkpoints, and the evaluation framework will be fully open-sourced.",
  venue={ACL 2024 Oral},
  selected={true}
}